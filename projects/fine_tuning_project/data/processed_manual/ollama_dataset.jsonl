{"prompt": "Explica 'task scheduler' (intervalos de cooldown).", "response": "Uso de conteos y fórmula de huecos: max(len, (maxCount-1)*(n+1)+numMax); o simular con heap; elegir según necesidad."}
{"prompt": "Explica 'circular house robber'.", "response": "Resolver robando [0..n-2] y [1..n-1] por separado y tomar el máximo; evita tomar primero y último juntos."}
{"prompt": "Explica bitmasking para subconjuntos y su enumeración eficiente.", "response": "Técnica: Representar subconjunto con bits; enumerar de 0..(1<<n)-1; probar pertenencia con (mask>>i)&1. | Ventaja: Operaciones de unión/intersección rápidas. | Complejidad: O(2^n). | Uso: DP sobre subconjuntos."}
{"prompt": "Explica 'serialize N-ary tree' por nivel.", "response": "Guardar número de hijos por nodo junto a valor; deserializar leyendo conteos; o usar separadores por nivel; múltiples esquemas válidos."}
{"prompt": "Explica búsqueda ternaria y cuándo no tiene ventajas sobre binaria.", "response": "Idea: Divide el rango en tres y reduce a dos tercios. | Complejidad: También O(log n), pero mayor constante y más comparaciones por paso. | Conclusión: No mejora a binaria para búsquedas discretas; útil solo en funciones unimodales continuas."}
{"prompt": "Explica 'hand of straights' con greedy y mapa frecuencias.", "response": "Ordenar keys, para cada valor usarlo como inicio usando k consecutivos decrementando conteos; si faltan, imposible."}
{"prompt": "Explica multi-source BFS y un ejemplo.", "response": "Inicializar la cola con múltiples nodos fuente (dist=0) y expandir simultáneamente. | Ejemplo: Distancia a la celda más cercana con 1 en una grilla. | Complejidad: O(V+E)."}
{"prompt": "Describe automata Aho–Corasick.", "response": "Trie de patrones + fallos estilo KMP para saltar al siguiente prefijo; permite buscar múltiples patrones en O(n + matches). | Construcción O(sum longitudes)."}
{"prompt": "Enumera todos los subconjuntos de {a,b,c} con backtracking.", "response": "Estrategia: En cada elemento, decidir incluir o no; cuando se procesan todos, registrar subconjunto. | Árbol binario de decisiones con 2^n hojas. | Orden: Lexicográfico si se respeta orden original. | Complejidad: O(n·2^n)."}
{"prompt": "Explica 'partition equal subset sum'.", "response": "Subset sum al objetivo total/2 con bitset o DP booleana; si bit objetivo es 1, es posible; cuidado con suma impar."}
{"prompt": "Explica el heap (priority queue) y una operación típica.", "response": "Definición: Estructura basada en montículo binario que permite extraer el elemento con prioridad (máximo o mínimo). | Operaciones: insert O(log n), extract O(log n), peek O(1), build-heap O(n). | Usos: Dijkstra, top-K, planificación. | Errores: Confundir heap con arreglo ordenado; no mantener la propiedad del montículo."}
{"prompt": "Explica 'Kruskal con DSU' para MST y manejo de aristas iguales.", "response": "Ordena por peso; en ties, el orden no importa mientras se eviten ciclos; DSU garantiza componentes; resultado puede no ser único."}
{"prompt": "Encuentra el pico en un arreglo (elemento mayor que vecinos) en O(log n).", "response": "Idea: Búsqueda binaria en función unimodal; si arr[mid]<arr[mid+1], mover low=mid+1, si no, high=mid; cuando low==high, pico. | Complejidad: O(log n). | Requisito: Considerar bordes como -∞ o manejar comparaciones."}
{"prompt": "Describe el truco de 'dos BFS' en árboles para diámetro y centro.", "response": "BFS desde arbitrario → A; BFS desde A → B; camino A-B es diámetro; el centro es el nodo medio de ese camino (1 o 2 nodos)."}
{"prompt": "Compara AVL vs rojo-negro.", "response": "AVL más estricto en balance → búsquedas más rápidas en promedio; rojo-negro más simple para inserciones/borrados con menos rotaciones. | Ambos garantizan O(log n)."}
{"prompt": "Explica 'set matrix zeroes' in-place con primera fila/columna.", "response": "Usar primera fila/col como marcadores de ceros; bandera para primera fila/col; segunda pasada para cero-ficar; O(1) extra."}
{"prompt": "Explica multiplicación de cadenas de matrices (Matrix Chain).", "response": "Problema: Parentizar producto de matrices para minimizar multiplicaciones escalares. | DP: dp[i][j]=min sobre k de dp[i][k]+dp[k+1][j]+coste(i..k, k+1..j). | Complejidad: O(n^3) tiempo, O(n^2) espacio. | Uso: Optimización de consultas."}
{"prompt": "Describe cómo implementar un 'autocomplete' eficiente con un trie.", "response": "Navegar al nodo de prefijo y hacer DFS limitado para recolectar k sugerencias; almacenar top-k en cada nodo acelera consultas (precomputado)."}
{"prompt": "Explica 'merge k sorted lists' y por qué heap.", "response": "Heap mínimo con cabezas de listas; extrae y push siguiente; O(n log k) donde n total de nodos; mejor que merge secuencial."}
{"prompt": "Explica Dijkstra y su restricción principal.", "response": "Definición: Algoritmo para caminos mínimos desde una fuente con aristas de peso no negativo. | Pasos: Inicializa dist=∞, dist[s]=0; usa cola de prioridad para extraer el de menor dist; relaja aristas. | Restricción: No funciona con pesos negativos. | Complejidad: O((V+E) log V) con heap. | Errores: No actualizar correctamente la cola de prioridad."}
{"prompt": "Explica 'edit distance' espacio O(min(n,m)).", "response": "Guardar solo la fila anterior y la actual; actualizar células en orden; reduce memoria de O(nm) a O(min(n,m))."}
{"prompt": "Explica 'burst balloons' DP por intervalos.", "response": "dp[l][r] = max valor al reventar entre (l,r) el último k; valor = dp[l][k]+dp[k][r]+nums[l]*nums[k]*nums[r]; sentinelas."}
{"prompt": "Define aristas críticas en MST y cómo detectarlas.", "response": "Arista crítica aparece en todo MST; con Kruskal, si es la única con ese peso que cruza cierto corte, es crítica. | Se prueba quitando/forzando la arista."}
{"prompt": "Encuentra la subcadena más larga sin repetir caracteres y analiza.", "response": "Enfoque: Ventana deslizante con mapa de última posición; expande right, si repite, mueve left a max(left, last+1). | Complejidad: O(n). | Errores: No actualizar left correctamente; manejo de índices."}
{"prompt": "Explica Manacher para palíndromos más largos (idea general).", "response": "Idea: Algoritmo lineal para encontrar palíndromos más largos centrados en cada posición usando simetrías. | Técnica: Expandir alrededor del centro usando información del palíndromo más a la derecha conocido. | Complejidad: O(n). | Uso: Problemas de palíndromos en tiempo lineal."}
{"prompt": "Explica por qué un BST degenerado tiene O(n).", "response": "Si se inserta en orden, el árbol se vuelve una lista; altura = n-1; operaciones de búsqueda/insert/borrar se vuelven O(n). | Solución: Usar balanceados (AVL, rojo-negro) o aleatorizar."}
{"prompt": "Explica 'palindromic subsequences' conteo DP.", "response": "dp[i][j] = dp[i+1][j] + dp[i][j-1] + (1 si s[i]==s[j]) - dp[i+1][j-1]; modular por tamaño; cuidado con dobles conteos."}
{"prompt": "Compara DP y greedy en 'jump game'.", "response": "Greedy desde la izquierda manteniendo el alcance máximo es O(n) y suficiente; DP también funciona pero es innecesario. | Pitfall: casos límite con ceros."}
{"prompt": "Explica un filtro de Bloom y sus pros/contras.", "response": "Definición: Estructura probabilística para probar pertenencia con falsos positivos pero sin falsos negativos. | Idea: Múltiples hashes marcan bits; para consultar, verifica bits. | Pros: Muy espacio-eficiente. | Contras: No dice qué elementos; no admite borrado simple. | Uso: Cachés, bases de datos."}
{"prompt": "Explica distancia de edición (Levenshtein).", "response": "DP: dp[i][j] = costo mínimo para transformar prefijo A en B con inserción, borrado, sustitución. | Transición: min(dp[i-1][j]+1, dp[i][j-1]+1, dp[i-1][j-1]+(A[i]!=B[j])). | Complejidad: O(nm). | Uso: Corrección ortográfica, fuzzy matching."}
{"prompt": "Explica búsqueda por exponenciación (exponential search) y cuándo usarla.", "response": "Idea: Duplicar el rango hasta sobrepasar el objetivo y luego aplicar binaria en ese rango. | Uso: Arreglos infinitos/streams o cuando longitud desconocida. | Complejidad: O(log pos). | Requisito: Datos ordenados."}
{"prompt": "Resuelve cambio de monedas (mínimo número) con DP y describe el enfoque.", "response": "Enfoque: DP bottom-up, dp[x]=min(dp[x], 1+dp[x-coin]) para cada moneda. | Inicializa dp[0]=0 y dp[otros]=∞; recorre x=1..target; para cada coin, actualiza si posible. | Complejidad: O(n*target). | Errores: No manejar imposible (dp[target]=∞)."}
{"prompt": "Da un ejemplo de heurística inconsistente en A* y el efecto.", "response": "Si h viola h(u) ≤ c(u,v)+h(v), f puede decrecer y A* podría reabrir nodos, perdiendo eficiencia; aún encuentra óptimo si h es admisible, pero puede expandir mucho más."}
{"prompt": "Describe el algoritmo de Moore para mayoría (>n/2).", "response": "Mantén un candidato y un contador; incrementa si coincide, decrementa si no; al final, verificar si realmente es mayoría. | Complejidad: O(n), O(1) espacio."}
{"prompt": "Explica la mochila 0/1 con DP.", "response": "Idea: Elegir artículos con peso y valor maximizando valor sin exceder capacidad. | DP: dp[i][w]=máximo con primeros i objetos y capacidad w; transición: max(dp[i-1][w], value_i+dp[i-1][w-weight_i]) si cabe. | Optimización: 1D descendente en w. | Complejidad: O(nW)."}
{"prompt": "Explica 'combination sum II' sin repetición.", "response": "Similar, pero avanza índice y salta duplicados en el mismo nivel; cada elemento se usa a lo sumo una vez."}
{"prompt": "Combina k listas ordenadas eficientemente y justifica la estructura.", "response": "Estrategia: Heap mínimo con la cabeza de cada lista; extrae mínimo y empuja su siguiente. | Complejidad: O(n log k) para n elementos totales. | Alternativas: Divide y vencerás O(n log k) también. | Ventaja: Simplicidad con heap."}
{"prompt": "Compara DP de tabla completa vs estados comprimidos.", "response": "Tabla completa: Fácil de razonar pero consume O(nm). | Estados comprimidos: Reducen a O(min(n,m)) u O(1) guardando solo lo necesario; complejidad temporal igual. | Ejemplo: LCS, knapsack 1D. | Elección: Memoria disponible."}
{"prompt": "Implementa un contador de rangos con diferencia de arrays (idea).", "response": "Técnica: Arreglo diff; para incremento en [l,r], diff[l]+=1 y diff[r+1]-=1; el arreglo real es el prefijo acumulado de diff. | Ventaja: Múltiples actualizaciones de rango en O(1) cada una. | Consulta: Reconstruir con prefix suma."}
{"prompt": "Explica cómo elegir la heurística h en A* para ser admisible y consistente.", "response": "Admisible: Nunca sobreestima la distancia real (h(n)≤h*(n)). | Consistente: h(n)≤c(n,m)+h(m); garantiza que f no disminuye en el camino. | Ejemplos: Distancia Manhattan en cuadrícula ortogonal. | Resultado: Optimalidad y eficiencia."}
{"prompt": "Se usa Dijkstra con pesos negativos y da resultados incorrectos. Explica la causa y solución.", "response": "Causa: Dijkstra asume no-negatividad para asegurar que la primera salida del heap es definitiva. | Solución: Usar Bellman-Ford o reponderación de Johnson si hay negativos sin ciclos negativos. | Advertencia: Dijkstra + negativos produce distancias subóptimas."}
{"prompt": "Explica por qué hashing de strings usa potencia modular.", "response": "Para permitir hash rodante H = Σ s[i]·p^i mod M; mover ventana actualiza en O(1) eliminando el término que sale y multiplicando por p."}
{"prompt": "Explica binary lifting para LCA (idea).", "response": "Idea: Preprocesar saltos de potencias de dos para cada nodo y su profundidad; elevar el más profundo hasta igualar, luego subir ambos buscando el ancestro común más bajo. | Complejidad: O(n log n) preprocess y O(log n) por consulta. | Uso: Árboles grandes."}
{"prompt": "Explica DFS y cuándo preferirlo sobre BFS.", "response": "Definición: Búsqueda en profundidad explora lo más profundo posible antes de retroceder. | Pasos: Visita nodo, marca, recorre vecinos recursivamente o con pila. | Uso: Detección de ciclos, tiempos de entrada/salida, componentes, topológico. | Comparación: DFS es más natural para backtracking; BFS para distancias mínimas. | Complejidad: O(V+E)."}
{"prompt": "Explica Kuhn y Hopcroft–Karp para matching bipartito.", "response": "Kuhn: DFS para augmenting paths O(VE). | Hopcroft–Karp: BFS capas + múltiples DFS, O(E√V). | Elegir según tamaño del grafo."}
{"prompt": "Calcula el número de componentes conexas en un grafo no dirigido.", "response": "Método: Itera vértices; si no visitado, lanza DFS/BFS y cuenta 1. | Complejidad: O(V+E). | Uso: Agrupar islas, detectar regiones. | Representación: Lista de adyacencia."}
{"prompt": "Define aristas de árbol, de avance, de retroceso y cruzadas en DFS.", "response": "Árbol: visitadas por primera vez; avance: a descendiente; retroceso: a ancestro; cruzadas: entre subárboles diferentes (en grafos dirigidos)."}
{"prompt": "Explica por qué quicksort no es estable por defecto.", "response": "Porque durante la partición se pueden intercambiar elementos iguales cambiando su orden relativo. | Soluciones: Partición estable (costo extra) o registrar índices/posiciones. | Implicación: Para ordenar por múltiples claves, usar mergesort o versión estable."}
{"prompt": "Explica 'min insertions to palindrome' como n - LPS.", "response": "LPS (longest palindromic subsequence); mínimo de inserciones = n - LPS; LPS por LCS(s, reverse(s))."}
{"prompt": "Convierte un topological sort (Kahn) a Python (idea) y explica la cola de 0 in-degree.", "response": "Idea: Calcular in-degree; encolar nodos con grado 0; extraer y decrementar grados de vecinos; si alguno llega a 0, encolar. | Final: Si orden tiene V nodos, era DAG; si no, había ciclos. | Estructuras: Cola, arreglo de grados, lista de adyacencia."}
{"prompt": "Explica 'matrix chain order' y parentización.", "response": "Guardar punto de corte k además de costo mínimo; reconstruir parentización óptima por recursión desde dp[0][n-1]."}
{"prompt": "¿Qué son las componentes fuertemente conexas (SCC) y cómo hallarlas?", "response": "Definición: Conjuntos de vértices en los que cada par es alcanzable mutuamente. | Métodos: Kosaraju (dos pasadas de DFS) o Tarjan (una pasada con pilas e índices). | Uso: Analizar módulos cíclicos, compresión de grafo. | Complejidad: O(V+E)."}
{"prompt": "Da un ejemplo de invariante en un bucle de inserción en ordenamiento por inserción.", "response": "Invariante: Antes de cada iteración i, el subarreglo [0..i-1] está ordenado. | Uso: Mantenerlo insertando key en su posición, desplazando mayores a la derecha. | Prueba: Inicialmente i=1 → trivial; preservación por inserción; al final, arreglo ordenado."}
{"prompt": "Explica 'Z vs prefix-function' diferencias prácticas.", "response": "Z compara contra prefijo global; pi compara prefijos de la cadena consigo misma; según el problema, uno resulta más directo."}
{"prompt": "Explica por qué ordenar por fin funciona en interval scheduling.", "response": "Intuición: Elegir el que termina antes deja más espacio para futuros intervalos; prueba por intercambio: si una solución óptima elige otro que termina después, cambiarlo no empeora y libera tiempo. | Resultado: Greedy óptimo."}
{"prompt": "Verifica si un grafo es bipartito y explica el procedimiento.", "response": "Idea: Un grafo es bipartito si se puede colorear con dos colores sin conflictos. | Método: BFS/DFS asignando colores alternos; si aparece una arista entre mismos colores, no lo es. | Uso: Emparejamientos, 2-coloring. | Complejidad: O(V+E)."}
{"prompt": "¿Qué es un deque y cuándo preferirlo?", "response": "Definición: Cola doble, permite inserciones/extracciones en ambos extremos. | Usos: ventana deslizante, BFS 0-1, mantener mínimos/máximos. | Ventajas: Flexibilidad con O(1) amortizado en extremos. | Errores: Usar estructuras equivocadas cuando solo se necesita stack/queue simple."}
{"prompt": "Explica 'word search II' optimización con podas.", "response": "Usar trie y eliminar nodos hoja tras encontrar palabra (pruning); corta ramas inútiles y mejora tiempo."}
{"prompt": "Explica el análisis amortizado con el ejemplo de un arreglo dinámico.", "response": "Idea: El coste promedio por operación es bajo aunque algunas sean caras. | Ejemplo: Vector que duplica capacidad al llenarse: expansión costosa O(n) pero ocurre poco; amortizado push es O(1). | Métodos: cuentas, potencial, agregación."}
{"prompt": "Explica KMP y el prefijo-sufijo (pi).", "response": "Idea: Evita retrocesos en el texto usando información del patrón. | Tabla pi: Para cada posición, longitud del mayor prefijo propio que es sufijo. | Búsqueda: Al fallo, saltar según pi[j-1]. | Complejidad: O(n+m). | Ventaja: Lineal sin retrocesos."}
{"prompt": "Diseña una solución para contar inversions en un arreglo.", "response": "Estratégia: Mergesort modificado que cuenta cuántos elementos del subarreglo derecho pasan antes que los del izquierdo durante la mezcla. | Complejidad: O(n log n). | Alternativa: Fenwick/segment tree con compresión de coordenadas."}
{"prompt": "Describe 'RMQ con sparse table' y por qué es O(1).", "response": "Precomputa min de bloques 2^k; una query [l,r] se contesta con dos bloques que cubren el rango; función idempotente permite esto."}
{"prompt": "Diseña un algoritmo para suma de subarreglo máxima (Kadane).", "response": "Enfoque: DP lineal; best_end = max(a[i], best_end + a[i]); best = max(best, best_end). | Complejidad: O(n). | Errores: Inicialización correcta con primer elemento; manejar todos negativos."}
{"prompt": "Realiza una traza paso a paso de la búsqueda binaria para encontrar 6 en [1,2,4,6,7,9].", "response": "Inicio: low=0, high=5. | Iteración 1: mid=2, arr[mid]=4, 6>4→low=3. | Iteración 2: mid=4, arr[mid]=7, 6<7→high=3. | Iteración 3: mid=3, arr[mid]=6, encontrado. | Resultado: índice 3. | Observación: Rango se reduce a la mitad en cada paso. | Complejidad: O(log n) tiempo."}
{"prompt": "Explica 'insert interval' correctamente.", "response": "Añadir nuevo intervalo y fusionar con vecinos; mantener orden; al final, consolidar; O(n)."}
{"prompt": "Explica 'merge intervals' y error común.", "response": "Ordenar por inicio; fusionar solapes; error común: no considerar igualdad (start ≤ fin) como solape; O(n log n)."}
{"prompt": "Explica 'union by size' versus 'by rank'.", "response": "Por tamaño une árbol pequeño bajo el grande; por rango usa estimación de altura; ambos logran amortizado casi O(1) con compresión."}
{"prompt": "Explica 'reconstruct itinerary' con Hierholzer.", "response": "Construir circuito euleriano lexicográfico con multigrafo; usar pila para backtracking; resultado invertido; O(E log E) por ordenamiento."}
{"prompt": "Explica por qué Union-Find con union por rango y compresión es casi O(1).", "response": "La complejidad amortizada es O(α(n)) con α(n) inversa de Ackermann, que crece lentísimo; en práctica constante. | Clave: Comprimir caminos y unir árbol pequeño debajo del grande."}
{"prompt": "Explica 'course schedule' como ciclo en DAG.", "response": "Problema de prerequisitos es detectar ciclo en grafo dirigido; usar Kahn o DFS; si no se procesan todos, hay ciclo."}
{"prompt": "Explica 'generate parentheses' con conteo.", "response": "Backtracking con dos contadores: abiertos restantes y cerrados disponibles; nunca cerrar más de lo abierto; generar bien formadas."}
{"prompt": "Explica 'wildcard matching' DP y greedy.", "response": "DP clásico; greedy alternativo guardando última '*' y backtracking cuando hay mismatch; más eficiente en práctica."}
{"prompt": "Une intervalos solapados y explica el procedimiento.", "response": "Pasos: Ordena por inicio; recorre y mantiene intervalo actual; si el siguiente solapa (start ≤ fin), extiende fin=max(fin, fin_siguiente), si no, almacena y reinicia. | Complejidad: O(n log n) por ordenamiento. | Errores: No considerar igualdad en solape."}
{"prompt": "Compara BFS con 0-1 BFS.", "response": "0-1 BFS usa deque: peso 0 → push_front, peso 1 → push_back; obtiene distancias mínimas en grafos con pesos 0/1. | BFS normal asume costo uniforme por arista. | Complejidad: O(V+E). | Ventaja: Evita Dijkstra en pesos 0/1."}
{"prompt": "Explica 'Splay tree' y cuándo conviene.", "response": "Autoajustable, mueve elemento accedido a la raíz; garantiza costo amortizado O(log n); bueno para accesos con localidad temporal."}
{"prompt": "Explica 'Prim con heap' para MST en grafo denso vs disperso.", "response": "En densos, matriz + O(V^2) puede ser mejor; en dispersos, lista + heap O(E log V) es preferible. | Elegir estructura adecuada."}
{"prompt": "Compara Dijkstra con y sin cola de prioridad.", "response": "Sin heap: seleccionar mínimo dist lineal O(V) por extracción→O(V^2)+O(E). | Con heap: O((V+E) log V). | Conclusión: En grafos dispersos, heap mejora mucho; en pequeños o muy densos, la diferencia puede ser menor."}
{"prompt": "Explica 'valid sudoku' comprobando reglas.", "response": "Usar sets por fila, columna y subcuadro 3x3; verificar duplicados al leer; O(81)."}
{"prompt": "Explica el 'low-link' y su significado.", "response": "low[u] = mínimo tin alcanzable desde u incluyendo retrocesos; permite detectar puentes (low[v] > tin[u]) y articulaciones."}
{"prompt": "Explica 'course schedule II' orden topológico resultado.", "response": "Tras Kahn/DFS, devolver orden obtenido si no hay ciclo; si hay ciclo, devolver vacío; validar tamaño == V."}
{"prompt": "Explica mochila fraccionaria y por qué greedy es óptimo.", "response": "Idea: Se permite fraccionar artículos; toma mayor valor/ peso primero. | Prueba: Intercambios muestran que ordenar por densidad valor/peso maximiza valor. | Pasos: Ordena por densidad; toma mientras haya capacidad; fracciona el último si no cabe. | Complejidad: O(n log n)."}
{"prompt": "Justifica por qué DP de coin change debe inicializar dp[0]=0 y no otro valor.", "response": "dp[0]=0 representa que para cantidad 0 no se usan monedas; cualquier otra cantidad inicialmente imposible (∞). | Sin esto, las transiciones 1+dp[x-coin] tendrían base inválida. | Resultado: Coherencia de óptimos."}
{"prompt": "Explica 'N-Queens' con bitmasks.", "response": "Usar máscaras para columnas, diag1, diag2; en cada fila, tomar posiciones válidas como bits y recursar; muy eficiente."}
{"prompt": "Explica tres formas de rotar un arreglo k posiciones a la derecha.", "response": "Métodos: (1) Rotación por reversa en tres pasos; (2) Usar arreglo auxiliar O(n); (3) Rotación por ciclos usando mcd(n,k). | Complejidad: O(n) tiempo; espacio O(1) en (1) y (3). | Errores: Calcular k% n."}
{"prompt": "Explica 'covering intervals con mínimo de puntos'.", "response": "Greedy: Ordena por fin y coloca un punto al final del primer intervalo, elimina los cubiertos, repite. | Correctitud: Prueba de intercambio."}
{"prompt": "Explica 'three-sum' con dos punteros.", "response": "Ordenar y para cada i, resolver 2-sum en [i+1..] con two pointers; saltar duplicados; O(n^2)."}
{"prompt": "Explica quicksort, su caso promedio y peores casos.", "response": "Idea: Elige pivote, particiona elementos menores a la izquierda y mayores a la derecha, y ordena subarreglos recursivamente. | Promedio: O(n log n) con pivotes balanceados. | Peor caso: O(n^2) si el pivote divide muy mal (por ejemplo, arreglos ya ordenados con pivote extremo). | Mitigación: Pivote aleatorio o mediana de tres. | Espacio: O(log n) promedio por profundidad de recursión. | Estabilidad: No estable por defecto."}
{"prompt": "Traza BFS desde A en el grafo A-B-C-D con aristas A-B, B-C, A-D.", "response": "Inicial: cola=[A], dist[A]=0. | Paso 1: pop A→visita B y D; dist[B]=1, dist[D]=1. | Paso 2: pop B→visita C; dist[C]=2. | Paso 3: pop D→no hay nuevos. | Paso 4: pop C→fin. | Resultado: niveles A:0, B:1, D:1, C:2."}
{"prompt": "Explica la pila monótona para siguiente mayor elemento.", "response": "Idea: Mantener pila de índices con valores decrecientes; al ver un valor mayor, resuelve para los índices en la pila. | Resultado: Para cada i, índice del siguiente mayor o -1. | Complejidad: O(n). | Uso: Histogramas, temperaturas diarias."}
{"prompt": "Explica DP para cadenas con patrón wildcard '?', '*'.", "response": "dp[i][j] verdadero si patrón[0..j] matchea texto[0..i]; '?' consume uno, '*' consume cero o más: dp[i][j] = dp[i][j-1] o dp[i-1][j]."}
{"prompt": "Compara 'next greater element' y 'next smaller element'.", "response": "Ambos con pila monótona; para NGE, pila decreciente; para NSE, pila creciente. | Aplicación: histogramas, temperaturas, stock span."}
{"prompt": "Elige una estructura para un LRU cache y justifica.", "response": "Solución: Hash map + lista doblemente enlazada. | Razón: O(1) para acceso por clave; lista mantiene orden de uso para expulsar el menos reciente en O(1). | Operaciones: get actualiza posición; put inserta/actualiza y expulsa si supera capacidad."}
{"prompt": "Explica recursión de cola y cuándo el compilador puede optimizarla.", "response": "Definición: La llamada recursiva es la última operación de la función. | Ventaja: Puede optimizarse a bucle (TCO), evitando crecer el stack. | Limitación: No todos los compiladores/entornos aplican TCO; en Python, no. | Ejemplo: Cálculo iterativo de factorial."}
{"prompt": "Encuentra la primera y última aparición de un valor en un arreglo ordenado.", "response": "Estrategia: Dos búsquedas binarias modificadas: una para el límite inferior (primera) y otra para el superior (última). | Detalle: Al encontrar igual, seguir buscando a la izquierda/derecha según caso. | Complejidad: O(log n)."}
{"prompt": "Explica 'longest valid parentheses'.", "response": "Pila de índices o DP; con pila, push -1 al inicio; al ver ')', pop; si vacía, push índice; si no, max con i - top()."}
{"prompt": "Explica el orden topológico y cuándo se aplica.", "response": "Definición: Orden lineal de los vértices de un DAG tal que todas las aristas van de antes a después. | Métodos: DFS con pila de finalización o Kahn con grados de entrada. | Uso: Planificación de tareas, dependencias de compilación. | Complejidad: O(V+E). | Restricción: Solo en DAG (sin ciclos)."}
{"prompt": "Explica 'combination sum' backtracking con repetición.", "response": "Ordenar candidatos; permitir reutilizar mismo índice; podar cuando excede target; evitar duplicados con orden."}
{"prompt": "Halla los N elementos más frecuentes y discute enfoques.", "response": "Hash de frecuencias + heap mínimo de tamaño N (O(n log N)); o bucket sort O(n) si rango de frecuencias acotado; o ordenar por frecuencia O(n log n). | Elección: Heap para N≪n. | Cuidado: Desempates deterministas si se requiere."}
{"prompt": "Explica la técnica de ventana deslizante con un ejemplo.", "response": "Idea: Mantener una subventana con propiedades, expandiéndola/contrayéndola para recorrer el arreglo en O(n). | Ejemplo: Longitud máxima de subcadena sin caracteres repetidos: mueve right, agrega; si hay repetido, mueve left hasta solventar. | Complejidad: O(n) amortizado."}
{"prompt": "Traza DFS (pre y post) en un árbol raíz 1 con hijos 2,3; 2 tiene 4,5.", "response": "Preorden: visita 1, 2, 4, 5, 3. | Postorden: 4,5,2,3,1. | Inorden (binario si 2 tiene izq=4, der=5): 4,2,5,1,3. | Observación: DFS explora hijos antes de hermanos. | Uso: Procesar dependencias."}
{"prompt": "Explica por qué 'binary lifting' requiere raíz y preprocesamiento DFS.", "response": "Se necesitan profundidades y ancestros directos por DFS/BFS; desde ellos se rellenan las potencias de dos iterativamente."}
{"prompt": "Compara estrategias de colisión en tablas hash.", "response": "Chaining: Lista/estructura por bucket; simple de implementar; robusto a altas cargas pero con listas largas. | Open addressing: Sonda en el arreglo; mejor localidad; requiere factor de carga controlado y buena sonda (lineal, cuadrática, doble hash). | Elección: Depende de memoria y accesos."}
{"prompt": "Explica búsqueda en matrices ordenadas por filas y columnas.", "response": "Desde la esquina superior derecha: si actual > x baja, si < x avanza a la derecha; O(n+m). | Alternativa: binaria por fila (si se sabe rango)."}
{"prompt": "Compara 'quadratic probing' con 'double hashing'.", "response": "Quadratic reduce clustering primario pero puede fallar en visitar todas las celdas; double hashing usa segundo hash y recorre toda la tabla."}
{"prompt": "Compara Union-Find vs BFS para consultas de conectividad en un grafo estático.", "response": "Grafo estático: Preprocesar con DFS/BFS por componente y responder en O(1). | Con many queries y uniones dinámicas: Union-Find es ideal (unir y consultar casi O(1)). | Si hay cambios de aristas arbitrarios: estructuras más avanzadas. | Elección: Depende de dinámica y número de consultas."}
{"prompt": "Explica por qué 'two-sum' con set funciona y posibles fallas.", "response": "Se guarda complementos; al ver a[i], si está en set, se encontró par; si no, añade (target - a[i]). | Fallas: Duplicados y necesidad de índices; cuidado al construir solución."}
{"prompt": "Muestra el particionado de quicksort con pivote 5 en [9,3,5,1,8].", "response": "Idea: Poner menores que 5 a la izquierda y mayores a la derecha. | Pasos: Compara 9>5→derecha; 3<5→izquierda; 5 pivote; 1<5→izquierda; 8>5→derecha. | Resultado de partición: [3,1,5,9,8] (posiciones pueden variar según implementación)."}
{"prompt": "Encuentra los top-K elementos más grandes con heap y analiza costes.", "response": "Estrategia: Mantener heap mínimo de tamaño K; insertar cada elemento y expulsar el menor si excede K. | Complejidad: O(n log K). | Alternativa: Ordenar todo O(n log n). | Ventaja: Mejor cuando K≪n."}
{"prompt": "Describe 'rope' para cadenas grandes.", "response": "Árbol balanceado con hojas como fragmentos; concat, split, substring en O(log n); útil en editores de texto."}
{"prompt": "Aplica la técnica 'binary search on answer' en un problema de capacidad mínima.", "response": "Idea: Buscar la menor capacidad C tal que una función de verificación 'puede(C)' es verdadera; si true, intenta menor; si false, mayor. | Requisitos: Monotonicidad de 'puede(C)'. | Ejemplo: Cargar paquetes en D días."}
{"prompt": "Convierte un pseudocódigo de BFS a Python y explica la estructura básica.", "response": "Estructura: Usar deque para cola, set para visitados, dict para distancias. | Pasos: Encolar origen, marcar visitado; mientras cola, pop izquierda, visitar vecinos no vistos y encolar. | Claves: Evitar re-encolar ya visitados; almacenar distancia como dist[u]+1."}
{"prompt": "Diseña un enfoque para encontrar el número de islas en una matriz.", "response": "Estrategia: DFS/BFS en grilla; recorre celdas y cuando encuentres '1' no visitado, lanza búsqueda marcando toda la isla; incrementa contador. | Complejidad: O(R·C). | Variantes: Union-Find por celda."}
{"prompt": "Describe cómo detectar articulaciones (puntos de corte).", "response": "DFS con tiempos de entrada y low-link; un nodo u es articulación si tiene hijo v con low[v] ≥ tin[u] (o raíz con ≥2 hijos). | Tarjan para low-link."}
{"prompt": "Explica 'longest palindromic substring' expand around center.", "response": "Para cada centro (i, i) y (i, i+1), expandir mientras s[l]==s[r]; O(n^2) tiempo, O(1) espacio; simple y efectivo."}
{"prompt": "Compara recorridos de árboles: inorden, preorden, postorden.", "response": "Inorden: izquierda, nodo, derecha (BST produce orden). | Preorden: nodo, hijos (útil para copiar/serializar). | Postorden: hijos, nodo (borrado/liberar o evaluar expresiones)."}
{"prompt": "¿Qué es una pila (stack) y en qué problemas se usa?", "response": "Definición: Estructura LIFO (último en entrar, primero en salir). | Operaciones: push, pop, top, vacío. | Usos: Evaluación de expresiones, recorrido DFS iterativo, backtracking, deshacer/rehacer. | Complejidad: Operaciones O(1). | Errores: Desbordamiento/underflow; olvidar verificar vacío antes de pop."}
{"prompt": "Explica trie con conteo de pasadas para borrar seguro.", "response": "Guarda contador de cuántas palabras pasan por cada nodo y cuántas terminan; al borrar, decrementa y elimina nodos con contador 0."}
{"prompt": "Describe heapsort y compáralo con quicksort.", "response": "Heapsort: Construye un montículo (heap máximo), extrae el máximo y lo coloca al final, repite. | Pasos: build-heap O(n); luego n extracciones O(log n) cada una. | Complejidad: O(n log n) tiempo, O(1) espacio extra. | Comparación: Heapsort garantiza O(n log n); quicksort suele ser más rápido en práctica por mejores constantes y localidad de memoria, pero puede degradar a O(n^2) si no se cuida el pivote."}
{"prompt": "Describe 'LCP array' y cómo se usa.", "response": "LCP[i] = longitud del prefijo común entre sufijos SA[i] y SA[i-1]; útil para contar substrings distintas y compresión."}
{"prompt": "Calcula el mínimo de salas de reuniones dadas listas de intervalos.", "response": "Enfoque: Barrido (sweep line) o min-heap. | Heap: Ordena por inicio; usa heap de finales; si inicio ≥ min(fin), libera sala; si no, nueva sala. | Complejidad: O(n log n). | Alternativa: Eventos +1 inicio, -1 fin."}
{"prompt": "Explica una cola (queue) y sus aplicaciones.", "response": "Definición: Estructura FIFO (primero en entrar, primero en salir). | Operaciones: enqueue, dequeue, frente, vacío. | Usos: BFS en grafos, planificación de tareas, buffers de datos. | Complejidad: Operaciones O(1) (cola circular o lista). | Variantes: Cola doble (deque) para operaciones en ambos extremos."}
{"prompt": "Explica 'rotten oranges' BFS multi-fuente.", "response": "Encolar todas las naranjas podridas con tiempo 0; expandir a frescas y contar minutos; si quedan frescas sin visitar, -1."}
{"prompt": "Explica por qué topological sort falla si hay ciclo.", "response": "En Kahn, no habrá suficientes nodos de in-degree 0 para procesar todos; la cola se vacía antes de contar V nodos. | En DFS, aparece una arista de retroceso (a un gris)."}
{"prompt": "Explica 'Treap' y su beneficio.", "response": "Combina BST por clave y heap por prioridad aleatoria; balance esperado O(log n); código simple, rotaciones basadas en prioridad."}
{"prompt": "Explica 'sliding window máximo' con heap lazy.", "response": "Mantener heap de valores con índices; al mover, descartar perezosamente los que salieron de ventana; más simple pero O(log n) por paso."}
{"prompt": "Elige entre Trie y HashMap para autocompletar por prefijo y justifica.", "response": "Trie: Búsqueda por prefijo O(L), enumeración de todas las palabras por subárbol; coste de memoria mayor. | HashMap: Rápido por clave exacta, pero no eficiente para listar por prefijo. | Conclusión: Trie es la opción natural para autocompletado por prefijo."}
{"prompt": "Describe 'reservoir sampling' para streaming.", "response": "Mantén k muestra de un stream de tamaño desconocido; cada nuevo elemento i se toma con prob k/i reemplazando al azar. | Garantiza uniformidad."}
{"prompt": "Explica mergesort y por qué es estable.", "response": "Definición: Divide y vencerás: divide el arreglo, ordena recursivamente y mezcla ordenado. | Pasos: Divide a mitades hasta tamaño 1; mezcla dos subarreglos ordenados preservando orden de iguales. | Estabilidad: En la mezcla, al tomar igual, elegir el de la izquierda mantiene el orden original. | Ejemplo breve: [3,1,2]->[3]|[1,2]→mezcla→[1,2,3]. | Complejidad: O(n log n) tiempo, O(n) espacio. | Uso: Datos grandes cuando se prefiere estabilidad."}
{"prompt": "Explica cómo hallar la mediana de dos arreglos ordenados en O(log n).", "response": "Idea: Búsqueda binaria sobre la partición correcta entre ambos arreglos para equilibrar mitades. | Condición: max(izqA, izqB) ≤ min(derA, derB). | Ajustar partición moviendo en el arreglo más pequeño. | Complejidad: O(log(min(n,m)))."}
{"prompt": "Explica 'binary lifting' para k-ésimo ancestro.", "response": "Precompute up[u][j] = 2^j-ésimo ancestro; para subir k, descomponer en bits y mover. | Complejidad: O(n log n) preprocess, O(log n) por consulta."}
{"prompt": "Explica 'random pick with weight' prefix + binaria.", "response": "Construir prefijos acumulados y bsearch sobre un número aleatorio en [1..sum]; probabilidad proporcional al peso."}
{"prompt": "Explica el 'activity selection con recursos múltiples' y complejidad.", "response": "Caso general es NP-duro; variantes se resuelven con flujos o DP; greedy simple no basta con múltiples recursos."}
{"prompt": "Explica la técnica de dos punteros con un ejemplo simple.", "response": "Idea: Usar dos índices que avanzan con reglas para aprovechar orden/propiedades. | Ejemplo: Dado arreglo ordenado, encontrar par que sume X: low=0, high=n-1; si suma alta, baja high; si baja, sube low. | Complejidad: O(n). | Ventaja: Evita O(n^2) doble bucle."}
{"prompt": "Encuentra el diámetro de un árbol y explica el truco de dos BFS.", "response": "Truco: BFS/DFS desde un nodo arbitrario para hallar el más lejano A; luego BFS desde A para hallar B y la distancia AB es el diámetro. | Complejidad: O(V+E) en árboles. | Intuición: Extremos de un camino más largo."}
{"prompt": "Determina si existe un ciclo impar para saber si un grafo no es bipartito.", "response": "Criterio: Un grafo es no bipartito si y solo si contiene un ciclo de longitud impar. | Detección: BFS con colores detecta conflicto (mismo color), lo cual implica ciclo impar. | Complejidad: O(V+E)."}
{"prompt": "Explica 'range add + range sum' con dos BITs.", "response": "Mantén BIT B1 y B2; suma en rango actualiza ambos; query de prefijo usa combinación prefix(x)=x*sum(B1)-sum(B2)."}
{"prompt": "Explica por qué KMP es lineal incluso con patrones repetitivos.", "response": "Porque al fallar, usa pi para saltar posiciones del patrón sin retroceder en el texto; cada carácter del texto se procesa a lo sumo dos veces."}
{"prompt": "Explica por qué 'tarjan SCC' usa pila y lowlink.", "response": "Pila para mantener el componente actual; lowlink detecta raíz de SCC cuando low[u]==tin[u], desempila hasta u para formar la SCC."}
{"prompt": "Explica 'binary search tree iterator' en-order.", "response": "Pila para desplazar al más izquierdo; next devuelve actual y baja por derecha; hasNext mientras pila no vacía; O(h) espacio."}
{"prompt": "Explica 'serialize/deserialize' de árbol binario (nivel).", "response": "Nivel con nulls para hijos faltantes; deserializar leyendo en orden y asignando hijos con una cola; robusto a árboles no completos."}
{"prompt": "Explica por qué la mediana minimiza suma de distancias L1.", "response": "En 1D, la función suma |x - a_i| es convexa por tramos y su mínimo se logra en cualquier mediana. | Intuición: Derivada cambiante por puntos a izquierda/derecha."}
{"prompt": "Explica 'suffix array' a alto nivel.", "response": "Arreglo de índices de sufijos ordenados lexicográficamente; permite búsqueda binaria de patrones; construcción O(n log n) o O(n)."}
{"prompt": "Explica por qué 'distinct subarrays by modulo' usa pigeonhole.", "response": "Si hay n números, los n prefijos mod n repiten un residuo → existe un subarreglo con suma múltiplo de n; prueba por principio del palomar."}
{"prompt": "Explica 'SOS DP' para sums over subsets.", "response": "Transformación que acumula valores para todos los superconjuntos/subconjuntos; O(n·2^n) sobre n bits; útil en conteos por máscara."}
{"prompt": "Explica por qué en knapsack 0/1 1D se itera w descendente.", "response": "Para no reutilizar el mismo objeto varias veces; si se hiciera ascendente, dp[w] usaría dp[w-weight] ya actualizado en esta ronda."}
{"prompt": "Planifica tareas con plazos y penalidades: explica una estrategia greedy clásica.", "response": "Estrategia: Ordenar por penalidad (o valor) descendente y programar lo más tarde posible antes del plazo usando estructura para slots (p. ej. DSU o array). | Justificación: Minimiza penalidad acumulada. | Complejidad: O(n log n) con heap/DSU. | Usos: Scheduling con deadlines."}
{"prompt": "Explica 'find median from data stream' dos heaps.", "response": "Mantener heaps balanceados; insertar y rebalancear; mediana es top del mayor o promedio de ambos; O(log n) por inserción."}
{"prompt": "Explica por qué quickselect halla el k-ésimo menor en promedio O(n).", "response": "Idea: Particiona como quicksort pero recursa solo en el lado relevante; pivote aleatorio da esperanza de balance. | Complejidad: Promedio O(n), peor O(n^2). | Comparación: Heaps pueden dar O(n log k) para top-k."}
{"prompt": "Define '2-SAT' y su resolución con SCC.", "response": "Construir grafo de implicación; si x y ¬x están en la misma SCC, insatisfacible; orden topológico de SCC da asignación. | O(V+E)."}
{"prompt": "Compara memoización vs tabulación con Fibonacci.", "response": "Memoización: Recursivo + cache por demanda; evita recomputos. | Tabulación: Iterativo bottom-up llenando tabla. | Ejemplo Fibonacci: memo O(n) tiempo y espacio; tabulación O(n) tiempo y O(1) espacio si solo se guardan dos últimos. | Elección: Tabulación más simple para dependencias lineales; memo para subproblemas esparsos."}
{"prompt": "Explica 'car pooling' (posible plan) con diferencia.", "response": "Convertir viajes a +capacidad en inicio y -capacidad en fin; ordenar eventos; acumular pasajeros y verificar no exceder cap."}
{"prompt": "Explica BFS en grafos y un ejemplo breve.", "response": "Definición: Búsqueda en anchura explora por capas usando una cola. | Pasos: Marca origen, encola; repite: desencola u, visita vecinos no marcados y encola. | Ejemplo: En una línea A-B-C-D desde A, distancias 0,1,2,3. | Usos: Distancia mínima en grafos no ponderados, niveles, bipartición. | Complejidad: O(V+E)."}
{"prompt": "Discute la diferencia entre subsecuencia y subcadena.", "response": "Subsecuencia: Mantiene orden pero no necesariamente contigüidad (LCS). | Subcadena: Debe ser contigua (longest substring). | Complejidad típica: LCS O(nm), substring sin repetir O(n). | Ejemplos: 'abc' es subsecuencia de 'axbyc', subcadena de 'xabcd'."}
{"prompt": "Describe Floyd-Warshall y su tabla de DP.", "response": "Idea: All-pairs shortest paths mediante programación dinámica. | DP: dist[i][j] = min(dist[i][j], dist[i][k]+dist[k][j]) iterando k como vértice intermedio. | Soporta: Pesos negativos sin ciclos negativos. | Complejidad: O(V^3). | Uso: Grafos pequeños/medianos con múltiples consultas de distancia."}
{"prompt": "Explica Bellman-Ford y en qué casos preferirlo.", "response": "Definición: Calcula caminos mínimos permitiendo pesos negativos y detecta ciclos negativos. | Pasos: Repite V-1 veces: relaja todas las aristas; luego verifica si hay mejora para detectar ciclo negativo. | Uso: Cuando hay pesos negativos o se requiere detección de ciclos negativos. | Complejidad: O(VE)."}
{"prompt": "Explica 'bitset DP' para subset sum.", "response": "Usar bitset donde bit x indica suma alcanzable; por cada número a, desplazar bitset a la izquierda y OR; rápido con operaciones a nivel de palabra."}
{"prompt": "Define heap-indexado y caso de uso.", "response": "Heap con acceso por índice de elemento (posición en heap) para soportar decrease-key eficiente. | Uso: Dijkstra clásico con decrease-key real. | Estructura: Heap + mapa id→pos."}
{"prompt": "Explica un árbol binario de búsqueda (BST) y su rendimiento.", "response": "Definición: Árbol donde para cada nodo, los valores del subárbol izquierdo son menores y los del derecho mayores. | Operaciones: búsqueda/inserción/borrado promedio O(log n), peor O(n) si se desbalancea. | Uso: Conjunto ordenado, rangos. | Errores: No rebalancear; tocar duplicados sin estrategia."}
{"prompt": "Traza Dijkstra en un grafo con A→B(1), A→C(4), B→C(2).", "response": "Init: dist[A]=0, dist[B]=∞, dist[C]=∞. | Extrae A: relaja B→1, C→4. | Extrae B: relaja C→min(4,1+2)=3. | Extrae C: fin. | Distancias: A=0, B=1, C=3. | Camino a C: A→B→C."}
{"prompt": "Describe A* a alto nivel y su heurística.", "response": "Idea: Extiende Dijkstra usando una heurística admisible h(n) que nunca sobreestima la distancia restante. | f(n)=g(n)+h(n), expande por mínimo f. | Uso: Rutas en mapas, juegos. | Requisito: h admisible (y consistente) para optimalidad. | Complejidad: Depende de h."}
{"prompt": "Explica 'Kahn con prioridades' para orden topológico lexicográfico mínimo.", "response": "Usar heap/priority queue en lugar de cola para extraer el menor elemento disponible; mantiene orden lexicográfico mínimo."}
{"prompt": "Explica por qué el método de barrido necesita orden de eventos consistente.", "response": "Ties: Procesar primero finales y luego inicios evita contar solapes dobles según definición; la convención afecta el resultado."}
{"prompt": "Explica el ordenamiento por selección con su análisis de complejidad.", "response": "Idea: Selecciona el mínimo y colócalo al inicio, repite para el resto. | Pasos: Para i=0..n-2, encuentra índice del mínimo en [i..n-1], intercambia con arr[i]. | Ejemplo: [3,1,2]→mín en [0..2]=1→swap con 3→[1,3,2]→mín en [1..2]=2→swap→[1,2,3]. | Complejidad: Siempre O(n^2) comparaciones; O(1) espacio. | Estabilidad: No estable por defecto. | Uso: Solo pedagógico o muy simple."}
{"prompt": "Explica 'four-sum' y por qué usar hash de pares.", "response": "Guardar sumas de pares y combinarlas con otras sumas para target; cuidado con duplicados; O(n^2) espacio/tiempo."}
{"prompt": "Resuelve T(n)=3T(n/2)+n con el maestro.", "response": "Datos: a=3, b=2, f(n)=n. | n^{log_b a}=n^{log_2 3}≈n^{1.585}. | f(n)=O(n^{1.585-ε})→Caso 1. | Resultado: T(n)=Θ(n^{log_2 3}). | Interpretación: Mayor que n log n, menor que n^2."}
{"prompt": "Explica por qué Bellman-Ford requiere V-1 iteraciones.", "response": "Cada iteración relaja caminos con a lo sumo k aristas; tras V-1, se han considerado todos los caminos simples (a lo sumo V-1 aristas). | Iteración extra detecta ciclos negativos si aún mejora."}
{"prompt": "Explica 'Kasai' para construir LCP en O(n).", "response": "Usa rank inverso y reusa la coincidencia anterior disminuyendo en 1 por paso; compara sufijos adyacentes en SA sin reiniciar."}
{"prompt": "Explica por qué Z-algorithm es útil en 'pattern in text'.", "response": "Concatena patrón '$' texto; Z[i] igual a longitud de prefijo que coincide → si Z ≥ |patrón| en alguna posición, hay match. | O(n)."}
{"prompt": "Explica 'Mo con updates' (tres dimensiones).", "response": "Extiende Mo con una tercera dimensión tiempo; mantener estructura al mover L, R y aplicar/revertir actualizaciones; más complejo y lento."}
{"prompt": "Describe codificación de Huffman y su construcción.", "response": "Idea: Árbol binario óptimo para códigos prefijo basados en frecuencias. | Pasos: Inserta frecuencias en heap mínimo; extrae dos mínimos, combínalos y re-inserta; repite hasta uno. | Resultado: Códigos más cortos para símbolos frecuentes. | Complejidad: O(n log n)."}
{"prompt": "Define lower_bound y upper_bound y su utilidad.", "response": "lower_bound: Primer índice con arr[i]≥x. | upper_bound: Primer índice con arr[i]>x. | Utilidad: Contar ocurrencias (upper-lower), insertar manteniendo orden, rangos. | Complejidad: O(log n)."}
{"prompt": "Define 'sparse table' y uso.", "response": "Precompute RMQ con potencias de dos; query en O(1) y O(n log n) preprocess; inmutable (no soporta updates). | Uso: min/max idempotentes."}
{"prompt": "Explica Rabin-Karp y el concepto de hash rodante.", "response": "Idea: Comparar hashes de ventanas del texto con hash del patrón; si coincide, verificar carácter a carácter. | Hash rodante: Permite actualizar el hash al mover la ventana en O(1). | Ventaja: Útil para múltiples patrones. | Complejidad: Promedio O(n+m), peor O(nm) por colisiones."}
{"prompt": "Define árbol k-ario heap y pros/contras.", "response": "Heap d-ario reduce altura (log_d n), menos extracciones, pero aumenta comparaciones por extracción. | Pros: Menos niveles → menos disminuciones. | Contras: Sift-down más costoso. | Uso: D mayor para muchas inserciones."}
{"prompt": "Explica sliding window con conteo de caracteres para anagramas.", "response": "Mantén frecuencias en ventana; al mover, actualiza; cuando coinciden con patrón, anagrama encontrado. | Complejidad: O(n + α) con α alfabeto."}
{"prompt": "Explica por qué LIS O(n log n) no da la secuencia sin rastreo.", "response": "Mantiene solo 'tails' mínimos; para reconstruir, hay que guardar predecesores e índices elegidos por cada posición. | Sin eso, solo obtienes la longitud."}
{"prompt": "Explica caminos mínimos en DAG con DP.", "response": "Estrategia: Orden topológico y relajación en ese orden. | Pasos: topological sort; inicializa dist; recorre vértices; relaja aristas salientes. | Requisito: DAG (sin ciclos). | Complejidad: O(V+E). | Ventaja: Soporta pesos negativos sin ciclos."}
{"prompt": "Explica 'convex hull trick' en DP lineal.", "response": "Para dp[i] = min_j (m_j x_i + b_j), mantener envolvente de rectas en estructura monotónica; consultas en O(1)/O(log n) según patrón."}
{"prompt": "Explica la estructura Union-Find (DSU) y sus operaciones.", "response": "Definición: Mantiene particiones disjuntas para unir conjuntos y consultar si dos elementos están conectados. | Operaciones: find con compresión de caminos, union por rango/tamaño. | Complejidad: Amortizada casi O(1) (α(n)). | Uso: Kruskal, conectividad dinámica. | Errores: No aplicar compresión de caminos."}
{"prompt": "Explica por qué Johnson permite all-pairs con negativos sin ciclos.", "response": "Idea: Reponderar aristas usando potenciales h(v) de Bellman-Ford para que todos los pesos sean no negativos; luego correr Dijkstra desde cada nodo. | Garantía: Caminos mínimos preservados tras reponderación. | Complejidad: O(VE+V E log V)."}
{"prompt": "Genera todas las permutaciones de [1,2,3] con backtracking (idea).", "response": "Idea: Construir permutación parcial; si tamaño==n, agregar; si no, probar elementos no usados, marcar, recursar, desmarcar. | Orden de generación: Léxico si iteras en orden. | Complejidad: O(n·n!). | Evita: Repetidos si hay duplicados (usar conteo)."}
{"prompt": "Aplica el método de la mediana de tres en quicksort y explica su efecto.", "response": "Idea: Elegir pivote como mediana de (primero, medio, último) para evitar peores casos en arreglos casi ordenados. | Efecto: Reduce probabilidad de particiones degeneradas; mejora rendimiento promedio. | Complejidad: Sigue siendo O(n log n) promedio."}
{"prompt": "Explica 'largest rectangle of 1s' en matriz.", "response": "Convierte cada fila en histogramas acumulando alturas de 1s y aplica el algoritmo del histograma en cada fila; O(R·C)."}
{"prompt": "Explica la búsqueda binaria a un estudiante de nivel básico con un ejemplo.", "response": "Definición: Búsqueda binaria localiza un elemento en una lista ordenada dividiendo el rango a la mitad repetidamente. | Cuándo usar: Cuando el arreglo está ordenado y necesitas búsquedas rápidas. | Pasos: Mantén índices low y high; calcula mid; compara target con arr[mid]; mueve low o high según el caso; repite hasta encontrar o vaciar el rango. | Ejemplo: En [1,3,5,7,9], buscar 7: mid=2→5<7→low=3; mid=3→7 hallado. | Complejidad: O(log n) tiempo, O(1) espacio. | Errores: Desbordes de índices; no actualizar correctamente low/high; usar en datos no ordenados."}
{"prompt": "Explica 'unique paths II' con obstáculos.", "response": "DP en grilla evitando celdas con obstáculo (ways=0); base primera fila/col se resetea ante obstáculos; O(R·C)."}
{"prompt": "Describe 'disjoint set of intervals' y estructura adecuada.", "response": "Mantener intervalos disjuntos con mapa ordenado; al insertar, fusionar con vecinos que solapan; consultas de pertenencia por lower_bound."}
{"prompt": "Explica 'number of islands' variación con diagonales.", "response": "Cambiar vecindad a 8 direcciones; BFS/DFS con 8 vecinos; cuenta componentes conectados considerando diagonales."}
{"prompt": "Compara lista de adyacencia vs matriz de adyacencia.", "response": "Lista: O(V+E) espacio; iterar vecinos en O(grado); insertar arista en O(1). | Matriz: O(V^2) espacio; comprobar arista en O(1); denso conveniente. | Elección: Lista para grafos dispersos; matriz para densos o consultas O(1) de existencia."}
{"prompt": "Explica 'segment tree beats' (visión general).", "response": "Segment tree avanzado que soporta operaciones como chmin/chmax y sum con podas; mantiene info extra y lazy; complejo pero potente."}
{"prompt": "Explica 'min window substring' idea.", "response": "Ventana deslizante con conteos requeridos; expande hasta cumplir, contrae manteniendo validez; guarda mejor longitud; O(n)."}
{"prompt": "Explica 'two-pointer' para triángulos válidos en un arreglo.", "response": "Ordenar; para cada k, usar i=0,j=k-1 y contar pares con a[i]+a[j]>a[k]; mover punteros adecuadamente; O(n^2)."}
{"prompt": "Explica 'SMAWK' para matrices totalmente monótonas.", "response": "Algoritmo que halla mínimos de cada fila en O(n); usa monocidad total para reducir columnas y recursión; avanza con filtrado."}
{"prompt": "Describe 'two-pointer' en array circular (subarrays con producto < K).", "response": "Ventana deslizante multiplicativa expandiendo y contrayendo; cuenta subarreglos al agregar cada elemento; cuidado con ceros."}
{"prompt": "Explica por qué Johnson usa potencias h para reponderar.", "response": "h(v) asegura que w'(u,v) = w(u,v) + h(u) - h(v) ≥ 0 y preserva diferencias de pesos de caminos; Dijkstra aplica en w' sin negativos."}
{"prompt": "¿Qué es un Fenwick tree (BIT) y en qué se diferencia de un segment tree?", "response": "Definición: Árbol binario indexado que soporta sumas prefix y actualizaciones en O(log n) con poca memoria. | Diferencia: Más simple y memoria O(n); pero menos flexible (difícil para min/max personalizados). | Uso: Sumas prefix, conteo de inversions. | Complejidad: O(log n)."}
{"prompt": "Define 'offline queries' con ordenamiento por bloque (Mo's algorithm).", "response": "Reordenar queries por bloques de tamaño ~√n y ordenar por bloque y R; mover L y R con actualizaciones O(1) amortizadas. | Útil en queries de rango estáticas."}
{"prompt": "Explica 'prefix function' en strings y un uso adicional a KMP.", "response": "Pi permite hallar periodos de la cadena: n - pi[n-1] si divide n; útil para compresión y mezcla de cadenas repetitivas."}
{"prompt": "Explica el ordenamiento burbuja y cuándo NO conviene usarlo.", "response": "Definición: Burbuja compara pares adyacentes e intercambia si están desordenados, repitiendo múltiples pasadas. | Cuándo usar: Solo para enseñanza o listas muy pequeñas casi ordenadas. | Pasos: Repite n-1 pasadas; en cada pasada, recorre y hace swaps cuando arr[i]>arr[i+1]. | Ejemplo: [3,1,2]→[1,3,2]→[1,2,3]. | Complejidad: O(n^2) tiempo, O(1) espacio. | No conviene: Con n grande; hay alternativas O(n log n) más eficientes."}
{"prompt": "Explica la relación entre ciclo negativo y Bellman-Ford.", "response": "Tras V-1 relajaciones, si alguna arista se puede relajar, existe ciclo negativo alcanzable; esto provoca que el camino mínimo no esté bien definido (tiende a -∞). | Acción: Reportar ciclo negativo. | Uso: Detección de arbitraje, errores."}
{"prompt": "Analiza T(n)=2T(n/2)+n y resuélvelo con el teorema maestro.", "response": "Forma: a=2, b=2, f(n)=n. | n^{log_b a}=n^{log_2 2}=n. | Caso 2: f(n)=Θ(n^log_b a). | Resultado: T(n)=Θ(n log n). | Ejemplo: Mergesort. | Observación: Término lineal por nivel y log niveles."}
{"prompt": "Explica 'shortest common supersequence' relación con LCS.", "response": "SCS(A,B) = |A| + |B| - LCS(A,B); para reconstruir, mezclar respetando LCS común y agregando caracteres restantes."}
{"prompt": "Explica 'lowest common ancestor' en BST simple.", "response": "Desde la raíz, si ambos < root, ir izquierda; si ambos > root, derecha; si divergen, root es LCA; O(h)."}
{"prompt": "Explica 'centroid decomposition' y uso.", "response": "Divide árbol por centroides para resolver queries globales con DP por niveles; útil en distancias y problemas de cobertura."}
{"prompt": "Explica la cola monótona para máximo en ventana deslizante.", "response": "Estrategia: Deque que mantiene valores decrecientes; al mover ventana, expulsar índices fuera y al insertar, quitar menores al final. | Consulta del máximo: El frente del deque. | Complejidad: O(n)."}
{"prompt": "Explica 'spiral matrix' de extracción.", "response": "Mantener límites top, bottom, left, right; recorrer bordes y ajustar límites; repetir mientras top ≤ bottom y left ≤ right."}
{"prompt": "Explica 'Divide & Conquer DP optimization'.", "response": "Si argmin es monotónico, la DP de costes separables se resuelve en O(n log n) por nivel; requiere estructura de convexe/monotónica."}
{"prompt": "Explica Dijkstra con decrease-key versus push duplicado.", "response": "Decrease-key reduce clave en heap (mejor complejidad teórica). | En práctica, se usa push duplicado y se ignoran entradas obsoletas al extraer (más simple y rápido). | Correctitud: Se valida dist actual antes de procesar."}
{"prompt": "Elige estructura para frecuencias con actualizaciones y consultas de rango.", "response": "Opciones: Fenwick para sumas prefix y actualizaciones punto; segment tree para operaciones más ricas (min, max, gcd). | Elección: Fenwick si solo sumas; segment tree si necesitas funciones asociativas generales. | Complejidad: O(log n)."}
{"prompt": "Explica 'regular expression matching' DP.", "response": "Patrón con '.' y '*'; dp[i][j] dependiendo si '*' toma 0 o más del char previo; base con patrones que pueden vaciarse."}
{"prompt": "Explica por qué 'interval scheduling' general con pesos requiere DP.", "response": "Con pesos, greedy por fin no funciona; se usa DP con p(i) (último compatible): dp[i]=max(dp[i-1], w_i+dp[p(i)]). | Ordenar por fin."}
{"prompt": "Explica 'lowest common ancestor' en árbol general con binary lifting.", "response": "Elevar el más profundo para igualar profundidades y luego subir ambos por potencias de dos hasta que sus padres coincidan; O(log n)."}
{"prompt": "Describe DSU rollback y uso.", "response": "Versión de Union-Find que permite deshacer uniones guardando cambios en una pila. | Uso: Offline queries con divide & conquer y rangos de tiempo. | Costo: O(log n) por cambios aplicados/ revertidos."}
{"prompt": "Explica subset sum con DP y su variante backtracking.", "response": "DP: Boolean dp[w] indica si hay subconjunto con suma w; inicial dp[0]=True; recorre elementos y actualiza descendente. | Complejidad: O(nW). | Backtracking: Recorrer decisiones incluir/excluir con poda por suma; peor caso exponencial, útil con n pequeño."}
{"prompt": "Explica por qué 'Fenwick' puede extenderse a 2D.", "response": "BIT 2D mantiene sumas por rectángulo con actualizaciones punto; complejidad O(log^2 n); índices 1-based y combinaciones de bits."}
{"prompt": "Explica 'design hit counter' con cola circular.", "response": "Guardar timestamps agregando conteos por segundo y limpiar fuera de ventana (300s); sumar al consultar; O(1) amortizado."}
{"prompt": "Explica 'restore IP addresses' backtracking.", "response": "Probar cortes de 1 a 3 dígitos validando rango y ceros a la izquierda; 4 segmentos exactos; poda por longitud restante."}
{"prompt": "Explica 'trapping rain water' con dos punteros.", "response": "Mantener maxLeft y maxRight; mover puntero de menor altura acumulando agua local; O(n), O(1) espacio."}
{"prompt": "Diseña un algoritmo para 'product of array except self' sin división.", "response": "Estrategia: Prefijos y sufijos: out[i]=pref[i-1]*suf[i+1]. | Pasos: Recorrer de izquierda a derecha acumulando pref; de derecha a izquierda acumulando suf multiplicando en out. | Complejidad: O(n) tiempo, O(1) espacio extra si se reutiliza out."}
{"prompt": "Calcula número de caminos en una grilla con DP (solo derecha/abajo).", "response": "DP: ways[i][j]=ways[i-1][j]+ways[i][j-1]; base: ways[0][*]=1 y ways[*][0]=1. | Complejidad: O(R·C). | Variante: Obstáculos → poner 0 donde haya barrera."}
{"prompt": "Explica 'alien dictionary' como topológico.", "response": "Derivar orden parcial comparando pares de palabras y la primera diferencia; construir grafo y hacer topological sort; detectar inconsistencias."}
{"prompt": "Diseña un algoritmo para detectar ciclos en un grafo dirigido.", "response": "Enfoque: DFS con colores (blanco, gris, negro) o Kahn. | DFS: Si alcanzas un vértice gris, hay ciclo. | Kahn: Si al remover nodos de grado de entrada 0 no procesas todos, hay ciclo. | Complejidad: O(V+E)."}
{"prompt": "Resuelve 2-sum y discute tres enfoques.", "response": "Hash: O(n) tiempo y O(n) espacio, guarda complementos. | Dos punteros: Requiere ordenado, O(n) después de ordenar. | Fuerza bruta: O(n^2). | Elección: Hash si orden no importa; dos punteros si ya está ordenado."}
{"prompt": "Explica 'Euler tour + segment tree' para path queries en árboles.", "response": "Mapea subárboles a rangos contiguos por tiempos de entrada; segment tree/fenwick responden sumas/min en subárboles."}
{"prompt": "Explica por qué Kadane sirve para todos negativos.", "response": "Inicializa best_end y best al primer elemento; así el máximo subarreglo puede ser el mayor (menos negativo) elemento individual."}
{"prompt": "Explica programación dinámica con bitmasks para TSP (idea).", "response": "Estado: dp[mask][u]=costo mínimo para visitar conjunto 'mask' y terminar en u. | Transición: dp[mask|1<<v][v] = min(dp[mask][u]+dist[u][v]). | Complejidad: O(n^2·2^n). | Uso: n pequeño (≤20)."}
{"prompt": "Explica counting sort y sus limitaciones.", "response": "Cuenta ocurrencias de cada valor en un rango pequeño, acumula prefijos y coloca establemente. | Complejidad: O(n+K) con K rango de valores. | Limitaciones: K debe ser razonable; requiere memoria O(K). | Uso: Preprocesamiento para radix sort."}
{"prompt": "Explica por qué un trie comprimido (radix tree) ahorra memoria.", "response": "Combina cadenas de nodos con único hijo en un solo arco etiquetado por subcadena; menos nodos y punteros, misma lógica de prefijos."}
{"prompt": "Explica 'digit DP' a alto nivel.", "response": "DP por posiciones de dígito con restricciones (límite, lleva, propiedades); estados (pos, tight, ...); recorre de MSB a LSB."}
{"prompt": "Diseña un algoritmo para validar un BST dado el árbol (rango).", "response": "Estrategia: DFS con límites (min,max); al ir a izquierda, max=valor actual; a derecha, min=valor actual; si un nodo viola límites, no es BST. | Complejidad: O(n). | Alternativa: Inorden debe ser estrictamente creciente."}
{"prompt": "Explica el patrón 'dos heaps' para mediana en streaming.", "response": "Idea: Heap máx para mitad inferior y heap mín para mitad superior; balancear tamaños para que difieran a lo sumo en 1; mediana es top de heap mayor (o promedio de ambos). | Complejidad: O(log n) por inserción. | Uso: Flujos de datos."}
{"prompt": "Compara Arreglo vs Lista enlazada para operaciones comunes.", "response": "Arreglo: index O(1), inserciones/borrados en medio O(n). | Lista: inserciones/borrados O(1) dado nodo, index O(n). | Elección depende del patrón de acceso."}
{"prompt": "Explica 'palindrome partitioning' backtracking + DP.", "response": "Precomputar palíndromos por DP; backtracking para cortes usando tabla; reduce costo de verificación."}
{"prompt": "Explica 'subsets II' (con duplicados) backtracking.", "response": "Ordenar y saltar duplicados cuando no se tomó el anterior; generar con decisión incluir/no incluir; evita repetidos."}
{"prompt": "Convierte DP de mochila 0/1 a Python (idea) y señala el detalle de iterar w descendente.", "response": "Estructura: dp de tamaño W+1 inicial 0. | Para cada objeto (valor, peso): iterar w de W hacia peso, dp[w]=max(dp[w], dp[w-peso]+valor). | Detalle crítico: Descender w evita reutilizar el mismo objeto múltiples veces."}
{"prompt": "Explica 'longest repeating character replacement'.", "response": "Ventana deslizante con frecuencia máxima en ventana; mantener condición ventana_len - max_freq ≤ k; expandir/contraer; O(n)."}
{"prompt": "Explica 'persistent segment tree' y caso de uso.", "response": "Versionado inmutable de segment tree permitiendo queries en versiones pasadas; útil para k-th menor en prefijo o histórico."}
{"prompt": "Define DAG shortest path con pesos negativos.", "response": "Es posible en O(V+E) si se hace orden topológico y relajación; pesos negativos no causan ciclos en DAG. | Útil cuando el grafo es acíclico por diseño (dependencias)."}
{"prompt": "Explica 'Min-Cost Max-Flow' con potentials.", "response": "Usa Dijkstra con potenciales para manejar pesos negativos entre iteraciones; repondera para evitar negativos; incrementa flujo con costo mínimo."}
{"prompt": "Explica 'maximum rectangle in histogram' con pila.", "response": "Mantener pila de índices con alturas crecientes; al ver menor altura, desapilar calculando áreas con la altura desapilada como mínima."}
{"prompt": "Explica 'reorder list' (L0→Ln→L1→Ln-1...).", "response": "Hallar mitad con slow/fast, invertir segunda mitad, intercalar nodos; O(n) tiempo y O(1) extra."}
{"prompt": "Explica por qué la búsqueda binaria requiere datos ordenados.", "response": "Razón: La decisión de descartar la mitad depende de saber que todos los elementos a un lado son menores/mayores; sin orden, no hay garantía. | Conclusión: Orden previo es condición necesaria; si no, usar hash o recorridos lineales."}
{"prompt": "Compara complejidad de mergesort linked list vs arreglo.", "response": "En listas, mergesort es natural y puede ser O(1) extra al intercalar nodos; en arreglos requiere O(n) extra. | Quicksort en listas es menos eficiente por partición difícil."}
{"prompt": "Explica 'Knuth optimization' (visión general).", "response": "Optimiza DP cuadrática con cuadrang. si se cumple monotonicidad de argmin; reduce a O(n^2). | Ej: DP de particionado óptimo."}
{"prompt": "Explica 'Heavy-Light Decomposition' (visión general).", "response": "Descompone árbol en caminos heavy y light para convertir path queries a O(log^2 n) sobre estructuras de rango."}
{"prompt": "Explica 'house robber' DP simple.", "response": "dp[i]=max(dp[i-1], dp[i-2]+nums[i]); base dp[0]=nums[0], dp[1]=max(nums[0],nums[1]); O(n) tiempo, O(1) espacio si se comprime."}
{"prompt": "Explica 'articulation bridges en 2D grid' y aplicación.", "response": "Modela celdas como nodos y aristas por adyacencia; puentes/ articulaciones señalan cuellos de botella; útil en mapas/juegos."}
{"prompt": "Explica búsqueda binaria sobre función monótona y da un ejemplo de verificación.", "response": "Idea: Buscar el menor x que cumple una condición monótona usando low/high y mid; si se cumple en mid, mueve high=mid, si no, low=mid+1. | Ejemplo: Capacidad mínima de contenedores para enviar paquetes en D días con función puede(C). | Complejidad: O(log R) verificaciones."}
{"prompt": "Explica 'Cartesian tree' y su relación con RMQ/LCA.", "response": "Árbol donde inorden da el arreglo y heap por valores; RMQ en arreglo = LCA en el árbol; útil para transformaciones de problemas."}
{"prompt": "Explica 'Dinic' y por qué es más rápido.", "response": "Construye 'level graph' y encuentra bloqueos con DFS; complejidad O(EV^2), mejor en práctica; para redes unitarias O(min{E^{1/2},V^{2/3}}E)."}
{"prompt": "Compara mergesort vs quicksort en datos aleatorios y casi ordenados.", "response": "Datos aleatorios: Ambos O(n log n); quicksort suele ser más rápido por constantes y caché. | Casi ordenados: Quicksort puede degradar si pivote es extremo; mergesort mantiene O(n log n). | Estabilidad: Merge estable, quick no. | Espacio: Merge O(n), quick O(log n)."}
{"prompt": "Explica 'binary search on tree answer' (k-th in path).", "response": "Usar HLD + estructuras ordenadas/fenwick por valor y binaria sobre respuesta; o persistent segment trees en Euler Tour."}
{"prompt": "Diseña una solución con dos punteros para detectar si hay par que sume X.", "response": "Pasos: Ordena arreglo; usa low y high; si suma> X, disminuye high; si < X, incrementa low; si == X, devuelve par. | Complejidad: O(n log n) por ordenamiento + O(n) dos punteros. | Alternativa: Hash set O(n) si no se requiere orden."}
{"prompt": "Explica cómo verificar paréntesis balanceados.", "response": "Estrategia: Pila; al ver apertura, push; al ver cierre, verifica top coincide y pop; al final, pila vacía. | Complejidad: O(n). | Extensión: Soportar múltiples tipos (), {}, []. | Errores: Pop en pila vacía."}
{"prompt": "Explica la estabilidad en ordenamiento con ejemplos.", "response": "Definición: Un algoritmo es estable si preserva el orden relativo de elementos iguales. | Ejemplos: Merge es estable; quick y heap no por defecto. | Importancia: Reordenar por múltiples claves sin perder orden previo. | Cómo: Diseñar mezcla que priorice izquierda en igualdad."}
{"prompt": "Da un ejemplo de 'rolling median' con dos heaps.", "response": "Heap máx para menores, heap mín para mayores; rebalancear cuando difieren en más de 1; mediana es top del heap mayor (o promedio si balanceado)."}
{"prompt": "Explica 'LRU cache' errores comunes.", "response": "No actualizar posición en get; olvidar eliminar nodo en borrar; mal manejo de punteros en extremos; usar sentinelas simplifica."}
{"prompt": "Explica la técnica de compresión de coordenadas.", "response": "Idea: Reemplazar valores grandes por índices compactos preservando orden. | Pasos: Copia y ordena únicos; asigna índice; reemplaza en los datos. | Uso: Fenwick/segment tree cuando valores son grandes. | Complejidad: O(n log n)."}
{"prompt": "Explica el árbol de segmentos (segment tree) con un ejemplo.", "response": "Definición: Estructura de árbol para consultas por rango (suma, mínimo, máximo) y actualizaciones en O(log n). | Idea: Divide el arreglo en segmentos; cada nodo resume un rango. | Ejemplo: suma en [l,r] y actualizaciones puntuales. | Complejidad: O(log n) por operación; O(n) construcción. | Uso: Consultas por rango frecuentes."}
{"prompt": "Explica por qué Floyd-Warshall permite reconstrucción de camino.", "response": "Al mantener una matriz next[i][j] con el primer salto en el camino mínimo y actualizarla al mejorar dist[i][j], se puede reconstruir el camino completo."}
{"prompt": "Explica 'balanced parentheses mínimo removals'.", "response": "Usar conteo para detectar excesos de ')' y pila/contadores para '('; o BFS por niveles eliminando un paréntesis y probando validez."}
{"prompt": "Explica por qué LIS con binaria mantiene el arreglo de 'tails'.", "response": "Razón: tails[len] guarda el menor posible final para una subsecuencia de longitud 'len+1'; reemplazar por valores menores amplía posibilidad de extender subsecuencia. | Búsqueda: lower_bound para encontrar posición. | Complejidad: O(n log n)."}
{"prompt": "Explica 'trie + DFS' para 'word search' en tablero.", "response": "Usar trie de palabras; DFS en la grilla siguiendo letras; marcar visitado temporalmente; poda al no encontrar prefijos."}
{"prompt": "Define 'corte mínimo' y relación con flujo máximo.", "response": "Teorema max-flow min-cut: valor del flujo máximo = capacidad del corte mínimo; corte biparticiona nodos; identifica cuellos de botella."}
{"prompt": "Explica 'evaluate division' con grafo ponderado.", "response": "Representar ecuaciones a/b=k como aristas ponderadas; query es producto de pesos en camino; usar DFS/BFS con multiplicación."}
{"prompt": "Explica 'split array largest sum' con binaria en respuesta.", "response": "Buscar mínimo mayor suma permitida para dividir en m subarreglos; verificación lineal acumulando y cortando cuando supera C."}
{"prompt": "Detecta ciclos en lista enlazada y explica el algoritmo de Floyd.", "response": "Método: Tortuga y liebre (punteros lento y rápido). | Pasos: Avanzar 1 y 2; si se encuentran, hay ciclo; para hallar entrada, reinicia uno a cabeza y avanza ambos a 1. | Complejidad: O(n) tiempo, O(1) espacio."}
{"prompt": "Explica LCS (subsecuencia común más larga) y su DP.", "response": "DP: dp[i][j] = LCS de prefijos A[0..i-1], B[0..j-1]. | Transición: Si A[i-1]==B[j-1], dp=1+dp[i-1][j-1]; si no, dp=max(dp[i-1][j], dp[i][j-1]). | Complejidad: O(nm) tiempo y O(min(n,m)) espacio con optimización. | Uso: Diferencias entre cadenas."}
{"prompt": "Explica el patrón de 'dos pilas para mínimo en O(1)' (min-stack).", "response": "Idea: Pila principal y pila de mínimos; al push, inserta min(valor, top_min) en la pila de mínimos; el mínimo actual es top de pila de mínimos; al pop, sacar de ambas. | Complejidad: O(1). | Uso: Seguimiento de mínimos."}
{"prompt": "Explica el método de barrido (sweep line) para eventos.", "response": "Idea: Transformar intervalos en eventos (inicio +1, fin -1), ordenar por tiempo y acumular un contador para conocer estados (p. ej. superposiciones). | Uso: Salas de reuniones, intersección de segmentos. | Complejidad: O(n log n)."}
{"prompt": "Describe DP para 'palíndromo mínimo por inserciones'.", "response": "DP[i][j] = min inserciones para hacer palíndromo A[i..j]; si A[i]==A[j], dp=dp[i+1][j-1], si no, 1+min(dp[i+1][j],dp[i][j-1])."}
{"prompt": "Explica mergesort externo (external sort).", "response": "Divide archivo en runs que caben en memoria, ordénalos, escribe; luego mezcla k-way en múltiples fases. | Uso: Datos que no caben en memoria. | I/O optimizado."}
{"prompt": "Explica diferencias entre stack y heap en memoria.", "response": "Stack: Almacena llamadas y variables locales; tamaño limitado; rápido; LIFO. | Heap: Memoria dinámica; manual o con GC; más lenta; fragmentación. | Errores: Desbordar stack con recursión profunda; fugas en heap por no liberar."}
{"prompt": "Explica selección aleatoria del pivote y su efecto.", "response": "Reduce probabilidad de peores casos en quicksort/quickselect; caso esperado O(n log n)/O(n). | CUIDADO: Semilla para reproducibilidad."}
{"prompt": "Describe 'max flow' con Edmonds–Karp.", "response": "BFS por capas encuentra camino aumentante más corto en aristas; O(VE^2). | Correctitud: Invariantes de corte mínimo/flujo máximo."}
{"prompt": "Explica 'word break' DP y backtracking.", "response": "DP booleana para verificable; para reconstruir, backtracking con memo guardando cortes válidos; usa trie o set para lookup."}
{"prompt": "Explica 'coin change ways' (número de formas).", "response": "DP 1D con sumas: dp[0]=1; para cada moneda, para x de coin..target, dp[x]+=dp[x-coin]; orden por monedas evita permutaciones."}
{"prompt": "¿Qué es la función prefijo (pi) y cómo se calcula?", "response": "Definición: Para cada posición i del patrón, longitud del mayor prefijo propio que coincide con sufijo que termina en i. | Cálculo: Avanzar i, mantener j como longitud actual; si patrón[i]==patrón[j], ++j; si no, j=pi[j-1] hasta que cuadre o 0. | Complejidad: O(m)."}
{"prompt": "Explica 'surrounded regions' (board) con DFS desde bordes.", "response": "Marcar 'O' conectadas a borde como seguras; luego convertir el resto a 'X'; finalmente restaurar seguras; evita capturar borde."}
{"prompt": "Explica 'clone graph' con hash map.", "response": "DFS/BFS copiando nodos y guardando mapeo original→copia; al visitar vecinos, enlazar usando el map; evita duplicados/ciclos."}
{"prompt": "Propón una variante de bucket sort y cuándo funciona.", "response": "Variante: Distribuir uniformemente en buckets por rango y ordenar cada bucket con inserción. | Funciona bien cuando los datos en [0,1) están uniformemente distribuidos. | Complejidad esperada: O(n). | Costo: Necesita conocer distribución."}
{"prompt": "Explica cómo detectar un ciclo en un grafo dirigido usando colores.", "response": "Colores: 0 no visitado, 1 en proceso, 2 terminado. | DFS: Al visitar, marca 1; si encuentras vecino 1, hay ciclo; al terminar, marca 2. | Complejidad: O(V+E). | Ventaja: Simple y claro."}
{"prompt": "Explica Kruskal y la utilidad de Union-Find.", "response": "Idea: Ordena aristas por peso y agrégalas mientras no formen ciclos, usando Union-Find para verificar conjuntos. | Pasos: sort E; para cada arista (u,v), si find(u)!=find(v), agrega y une. | Herramienta: Union-Find con compresión de caminos y unión por rango. | Complejidad: O(E log E)."}
{"prompt": "Describe LIS (longest increasing subsequence) y dos métodos.", "response": "Método DP simple: O(n^2) revisando previos; dp[i]=1+max(dp[j]) para j<i con a[j]<a[i]. | Método binario: O(n log n) manteniendo arreglo de colas (tails) y usando búsqueda binaria para reemplazar. | Resultado: Longitud de LIS y reconstrucción si se guarda predecessor."}
{"prompt": "Chequea si un grafo es 2-coloreable (coloración) y su procedimiento.", "response": "Método: BFS/DFS con dos colores alternos; si encuentras arista entre nodos del mismo color, falla. | Requisito: Grafo sin ciclos impares. | Complejidad: O(V+E). | Uso: Particionar en dos conjuntos independientes."}
{"prompt": "Explica por qué DP en cuadrícula usa base 'primera fila/columna'.", "response": "Son rutas únicas al avanzar solo derecha/abajo; base permite construir el resto por recursión: ways[i][j] = ways[i-1][j] + ways[i][j-1]."}
{"prompt": "Describe radix sort LSD y cuándo preferirlo.", "response": "Ordena dígito a dígito desde el menos significativo usando counting sort estable. | Ventaja: O(d·(n+K)) para d dígitos; útil cuando d es pequeño y K limitado. | Uso: Enteros de ancho fijo, strings cortos. | Requisito: Estabilidad en la pasada."}
{"prompt": "Explica 'rotate image' (matriz NxN).", "response": "Transponer y luego invertir cada fila (o capas por anillos); O(n^2) tiempo, in-place."}
{"prompt": "Explica selección de actividades (interval scheduling) con greedy.", "response": "Enfoque: Ordenar por tiempo de finalización y seleccionar intervalos compatibles. | Pasos: Ordena por fin; toma el primero; toma el siguiente que empiece después del fin actual; repite. | Correctitud: Prueba de intercambio. | Complejidad: O(n log n)."}
{"prompt": "Explica DP de edición con costo de operaciones diferentes.", "response": "La transición general: min(deleción + cost_del, inserción + cost_ins, sustitución + cost_sub), con una matriz dp; basta ajustar los costos por operación."}
{"prompt": "Analiza la complejidad de un doble bucle anidado i en [0..n) y j en [0..i).", "response": "Conteo de iteraciones: Suma de 0+1+...+(n-1)=n(n-1)/2. | Complejidad: O(n^2). | Espacio: O(1) si no hay estructuras adicionales. | Observación: Triángulo inferior de la matriz de iteraciones."}
{"prompt": "Explica 'word ladder' con BFS bidireccional.", "response": "BFS desde inicio y fin, expandiendo la frontera más pequeña; genera patrones con comodines para vecinos; mejora sobre BFS simple."}
{"prompt": "Explica 'bipartite matching' como flujo.", "response": "Modelar bipartito con fuente conectada a U y V al sumidero, capacidades 1; matching máximo = flujo máximo. | Integridad por capacidades enteras."}
{"prompt": "Explica el algoritmo de Prim para MST.", "response": "Definición: Construye un árbol de expansión mínima agregando la arista más barata que conecta un nuevo vértice al conjunto. | Pasos: Inicia en un vértice; usa un heap por corte de aristas mínimas; añade el menor costo que expande. | Complejidad: O(E log V) con heap. | Comparación: Similar objetivo a Kruskal, distinto enfoque."}
{"prompt": "Explica por qué el teorema maestro no aplica siempre.", "response": "Limitaciones: Requiere subproblemas del mismo tamaño y particiones regulares; f(n) polinomialmente relacionada con n^{log_b a}. | Casos no cubiertos: Subproblemas de tamaños distintos, recursiones no uniformes, f(n) irregular. | Alternativas: Recursión Akra–Bazzi."}
{"prompt": "Discute dos módulos y dos bases para reducir colisiones en Rabin-Karp.", "response": "Usar doble hash con distintos primos y bases minimiza probabilidad de colisiones coincidentes; verifica ambos antes de confirmar match."}
{"prompt": "Explica 'meet-in-the-middle' en subset sum.", "response": "Divide conjunto en dos mitades, genera sumas de cada mitad, ordena una y busca complementos por binaria; O(2^(n/2) log). | Útil para n≈40."}
{"prompt": "Explica el algoritmo Z y su utilidad.", "response": "Definición: Arreglo Z[i] = mayor coincidencia del prefijo empezando en i. | Construcción: Mantiene ventana [l,r] de coincidencias y la reutiliza. | Uso: Búsqueda de patrones, coincidencias repetidas. | Complejidad: O(n). | Comparación: Similar objetivo a KMP con otra tabla."}
{"prompt": "Define grafo bipartito y un criterio con matching máximo.", "response": "Un grafo es bipartito si no tiene ciclos impares; además, König: tamaño del matching máximo = tamaño del vertex cover mínimo en bipartitos."}
{"prompt": "Explica 'walls and gates' BFS multi-fuente.", "response": "Encolar todas las puertas (0) y expandir calculando distancias mínimas en celdas INF; paredes (-1) bloquean; O(R·C)."}
{"prompt": "Explica 'top k frequent words' desempate lexicográfico.", "response": "Heap con comparador por frecuencia desc y palabra asc; o contar y ordenar; importante criterio de desempate consistente."}
{"prompt": "Explica edición con transposición (Damerau-Levenshtein).", "response": "Permite operaciones de inserción, borrado, sustitución y transposición de adyacentes; DP ampliada con memoria de posiciones. | Útil en corrección tipográfica."}
{"prompt": "Explica el algoritmo de multiplicación rápida (exponenciación binaria).", "response": "Idea: Expresar exponente en binario; si bit=1, multiplica al acumulador; cada paso, cuadrar base y desplazar exponente. | Complejidad: O(log e). | Uso: Potencias grandes modulares. | Errores: Desbordes si no usas módulo."}
{"prompt": "Demuestra el coste de build-heap sobre un arreglo.", "response": "Hecho: Build-heap por heapify desde n/2 hasta 1 cuesta O(n). | Intuición: Pocos nodos profundos tienen costos altos pero su número decrece; suma geométrica domina por n. | Resultado: Heapsort O(n log n) tras O(n) de construcción."}
{"prompt": "Explica 'Pacific Atlantic water flow' BFS/DFS inversa.", "response": "Iniciar desde costas Pacífico y Atlántico y marcar alcanzables inversamente; intersección da celdas que fluyen a ambos."}
{"prompt": "Explica puentes en grafos y su detección.", "response": "Arista (u,v) es puente si low[v] > tin[u] en DFS; al eliminarla, aumenta componentes. | Se calcula en O(V+E)."}
{"prompt": "Explica 'LFU cache' idea.", "response": "Hash key→(val,freq) y map freq→lista de keys en LRU; minfreq para expulsar; O(1) amortizado para get/put con estructuras cuidadas."}
{"prompt": "Compara ordenamientos in-place y no in-place.", "response": "In-place: Usa O(1) espacio adicional (quicksort típico). | No in-place: Requiere espacio extra (mergesort clásico O(n)). | Impacto: Memoria y caché; in-place ahorra memoria pero puede ser más complejo. | Elección: Según restricciones."}
{"prompt": "Describe el algoritmo de inserción y sus ventajas sobre burbuja.", "response": "Definición: Inserción construye un arreglo ordenado insertando cada elemento en su posición en la porción izquierda. | Ventajas: Funciona muy bien con datos casi ordenados y es estable. | Pasos: Para i de 1..n-1, guarda key=arr[i], desplaza elementos mayores a la derecha, inserta key. | Ejemplo: [3,1,2]→coloca 1 antes de 3→[1,3,2]→coloca 2 entre 1 y 3→[1,2,3]. | Complejidad: Promedio/peor O(n^2); mejor O(n) si casi ordenado. | Estable: Sí."}
{"prompt": "Traza una pasada de Kahn en un DAG simple y muestra el orden resultante.", "response": "Ejemplo: A→B, A→C, B→D, C→D. | In-degree: A=0,B=1,C=1,D=2. | Cola inicial: [A]; saca A→decrementa B,C→0→[B,C]; saca B→D=1; saca C→D=0→[D]; saca D. | Orden: A, B, C, D (o A,C,B,D)."}
{"prompt": "Explica 'decode ways' DP.", "response": "dp[i] depende de dp[i-1] si s[i] válido (1-9) y dp[i-2] si s[i-1..i] válido (10-26); manejar ceros con cuidado."}
{"prompt": "Explica por qué 'median of two sorted arrays' requiere partición válida.", "response": "Condición max(leftA,leftB) ≤ min(rightA,rightB); garantiza que la mediana está en los bordes de la partición combinada."}
{"prompt": "Explica el patrón de dos pilas para implementar una cola.", "response": "Idea: Pila de entrada para enqueue y pila de salida para dequeue; al vaciar salida, volcar entrada a salida invirtiendo orden. | Complejidad: Amortizada O(1) por operación. | Errores: No volcar solo cuando salida esté vacía."}
{"prompt": "Explica por qué 'probing lineal' requiere factor de carga controlado.", "response": "Clustering primario degrada rendimiento a medida que la tabla se llena; mantener load factor < 0.7 y usar doble hashing/quadratic ayuda."}
{"prompt": "Explica 'median of data stream' con orden estadístico.", "response": "Alternativa con order-statistics tree para soportar deletes; más complejo; heaps son suficientes si no hay borrados."}
{"prompt": "Diseña un algoritmo para detectar un ciclo en grafo no dirigido.", "response": "Método DFS: Pasar nodo padre en la recursión; si encuentras vecino visitado distinto de padre, hay ciclo. | Alternativa: Union-Find detecta ciclo al intentar unir dos vértices ya conectados. | Complejidad: O(V+E)."}
{"prompt": "Explica 'permutations II' (con duplicados) backtracking.", "response": "Usar contador de ocurrencias por valor; elegir valores con count>0, decrementar y backtrack; evita duplicados naturalmente."}
{"prompt": "Explica qué es un trie y un caso de uso típico.", "response": "Definición: Árbol de prefijos para cadenas donde cada nodo representa un prefijo. | Operaciones: insertar, buscar, borrar, listar por prefijo. | Uso: Autocompletado y verificación de diccionarios. | Complejidad: O(L) por operación donde L es longitud de la palabra. | Espacio: Alto si no se comprime; mitigable con punteros compactos o DAWG."}
{"prompt": "Explica 'minimum palindrome cuts' DP.", "response": "dp[i]=mín cortes para s[0..i]; dp[i]=min(dp[j]+1) para j<i y s[j+1..i] palíndromo; base dp[i]=0 si s[0..i] ya palíndromo."}
{"prompt": "Explica 'offline range add + point query' con diferencia y prefix.", "response": "Aplicar todas actualizaciones a un diff y luego hacer prefijos; para queries puntuales, basta leer prefijo en la posición."}
{"prompt": "Explica por qué el algoritmo de Kruskal produce un MST.", "response": "Justificación: Propiedad del corte: la arista mínima que cruza cualquier corte pertenece a algún MST; Kruskal siempre escoge aristas mínimas que no forman ciclos; así construye un árbol válido y mínimo. | Correctitud: Prueba por intercambio y propiedad de corte."}
{"prompt": "Diseña un chequeo de palíndromo ignorando no alfanuméricos.", "response": "Enfoque: Dos punteros sobre la cadena; avanza hasta caracteres alfanuméricos; compara case-insensitive; si difiere, no palíndromo; si cruzan, sí. | Complejidad: O(n)."}
{"prompt": "Explica la resolución de sudokus por backtracking.", "response": "Idea: Buscar celda vacía, intentar dígitos válidos (sin repetir en fila, columna, subcuadro); recursar; si no hay opción, retroceder. | Poda: Ordenar por celda más restringida (MRV) acelera. | Complejidad: Exponencial en peor caso; práctica: rápido con buenas podas."}
{"prompt": "¿Qué es un AVL y qué garantiza?", "response": "Definición: BST auto-balanceado que asegura que las alturas de subárboles difieran a lo sumo en 1. | Garantía: Operaciones O(log n) en peor caso. | Mecanismo: Rotaciones simples y dobles tras inserciones/borrados. | Uso: Cuando la peor cota O(log n) debe mantenerse. | Desventaja: Constantes mayores que BST simple."}
{"prompt": "Resume los árboles rojo-negro y su objetivo.", "response": "Definición: BST balanceado con reglas de coloración que limitan la altura. | Objetivo: Mantener O(log n) garantizado para operaciones básicas. | Reglas: Nodo rojo no puede tener hijo rojo; todo camino a hojas nulas tiene igual número de negros. | Ventaja: Buen rendimiento en práctica; se usa en librerías estándar."}
{"prompt": "Explica 'order statistics tree' y operaciones.", "response": "BST balanceado con tamaño de subárbol para seleccionar k-ésimo o rank; soporta insert/borrar/buscar/rank/select en O(log n)."}
{"prompt": "Explica 'interleaving string' DP.", "response": "dp[i][j] verdadero si s3[0..i+j-1] formado por mezcla de s1[0..i-1] y s2[0..j-1]; transiciones por coincidencia de caracteres."}
{"prompt": "Resuelve N-Reinas (N=4) con backtracking y explica la poda.", "response": "Enfoque: Colocar reinas fila por fila evitando columnas y diagonales ocupadas. | Poda: Si una posición ataca o es atacada, no seguir; usar conjuntos para col, diag1, diag2. | Soluciones N=4: [1,3,0,2] y [2,0,3,1]. | Complejidad: Exponencial, mitigada por poda."}
{"prompt": "Explica 'serialize/deserialize' por preorden con marcadores.", "response": "Preorden incluyendo marcadores '#' para null; deserializar leyendo secuencia recursivamente; reconstruye estructura exacta."}
{"prompt": "Explica el concepto de colisiones en hashing y cómo mitigarlas.", "response": "Colisión: Dos claves mapean al mismo índice. | Mitigación: Buen hash con distribución uniforme; redimensionar al superar factor de carga; chaining con listas o open addressing bien parametrizado; verificación de igualdad tras hash. | Práctica: Usa primos en tamaño y doble hashing."}
{"prompt": "Explica Big-O, Big-Theta y Big-Omega con ejemplos.", "response": "Big-O: Cota superior asintótica (f(n)∈O(n^2)). | Big-Ω: Cota inferior (f(n)∈Ω(n)). | Big-Θ: Cota ajustada (f(n)∈Θ(n log n)). | Ejemplo: Mergesort es Θ(n log n); inserción es O(n^2) y Ω(n). | Uso: Comparar crecimiento de costes."}
{"prompt": "Explica por qué BFS encuentra la ruta más corta en grafos no ponderados.", "response": "Razón: BFS explora por capas de distancia creciente; la primera vez que visitas un nodo es por el camino con menos aristas. | Demostración: Inducción por capa. | Restricción: Pesos unitarios o iguales."}
{"prompt": "Explica el patrón dos pilas para evaluar expresiones infijas (idea).", "response": "Idea: Pilas de operandos y operadores; manejar precedencia y paréntesis: al ver operador, desapilar operadores de mayor/igual precedencia y aplicarlos; push nuevo operador; al final, vaciar. | Complejidad: O(n). | Cuidado: Precedencia y asociatividad."}
{"prompt": "Explica la diferencia entre BFS con lista de adyacencia y matriz en densidad distinta.", "response": "Lista: Recorrer vecinos reales, O(grado). | Matriz: Revisar todas las columnas, O(V). | Grafos dispersos: lista es más eficiente; densos: matriz puede ser aceptable. | Complejidad total: O(V+E) vs O(V^2)."}
{"prompt": "¿Cómo funciona una tabla hash y qué estrategias hay contra colisiones?", "response": "Idea: Aplica una función hash a la clave para ubicar un bucket donde se almacena el par clave-valor. | Colisiones: chaining (listas por bucket) o open addressing (lineal, cuadrática, doble hash). | Complejidad: Promedio O(1) para insertar/buscar; peor O(n). | Errores: No redimensionar al superar factor de carga; mala función hash."}
{"prompt": "Corrige un error típico en búsqueda binaria que produce bucle infinito.", "response": "Problema: Actualizar mal low/high, p. ej., usar mid en ambos extremos. | Corrección: Cuando arr[mid]<target, low=mid+1; cuando >target, high=mid-1; recalcula mid cada vez. | Asegurar condición: while low<=high. | Verificar overflow: mid=low+(high-low)/2."}
{"prompt": "Explica 'k closest points to origin' con heap.", "response": "Heap máximo de tamaño k con dist^2; mantener top-k más cercanos; O(n log k) tiempo; evitar sqrt."}
